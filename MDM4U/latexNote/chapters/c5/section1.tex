\section{Probability Distributions}
\subsection{Definitions for Probability Distributions}
\begin{cyanblock}
    \begin{definition}
        [Random Variable] A variable whose values are numerical outcomes of a random phenomenon, such as a probability experiment. 
    \end{definition}

    \begin{definition}
        [Discrete random variable] A random variable that hs a FINITE number of possible values in a given interval. Examples include number of books, shoe sizes
        , and report card marks
    \end{definition}

    \begin{definition}
        [Continuous variable] A random variable that can have an INFINITE number of possible values in a given interval. Examples include height, time, distance and money
    \end{definition}
\end{cyanblock}

\begin{cyanblock}
    \begin{definition}
        [Probability Distribution] The use of it illustrate the PROBABILITY of all possible outcomes of an experiment. The illustration may be in the form of 
        a table of values, a graph, or an equation
    \end{definition}

    \begin{definition}
        The probability that a discrete random variable $X$ have a particular value $x$ is expressed as $P(X = x)$ or $P(x)$
    \end{definition}

    \begin{definition}
        The expected value, $E(x)$ of a random variable $X$ is the predicted MEAN of all possible outcomes of a probability experiment. If $X$ is discrete, 
        then 
        \begin{gather*}
            E(x) = \Sigma x_i P(x_i)
        \end{gather*}
        and 
        \begin{gather*}
            \sigma = \sqrt{
                \Sigma (x - E(x))^2 P(x) 
            }
        \end{gather*}
    \end{definition}
\end{cyanblock}
